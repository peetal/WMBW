---
title: "WMBW_Gordon333"
output: html_document
---

```{r setup, include=FALSE, cache = TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning=FALSE,message=FALSE}
library(rio)
library(tidyverse)
library(sjmisc)
library(DescTools)
library(tidymodels)
library(janitor)
library(magrittr)
library(doParallel)
library(kableExtra)
#library(Rmisc)
library(afex)
library(cocor)
```

### Check and remove potential outliers (behavioral and neural)
```{r outlier_check}
rm(list = ls())

# load in the COPE11 data with Gordon333 parcellation scheme applied:
gordon333_cope11 <- import(here::here('./data/wm_gordon_cop11_pe_2mm_333.csv'))
# load in behavioral results (2-back, list-sorting, Pmat, picVocalb, reading_recog)
behavioral <- import(here::here('./data/HCP_behavioral_data.csv')) %>%
  select(Subject, WM_Task_2bk_Acc, ListSort_AgeAdj, PMAT24_A_CR, PicVocab_AgeAdj, ReadEng_AgeAdj)
# merge and remove na
working_df <- inner_join(gordon333_cope11, behavioral, by = 'Subject') %>% 
  na.omit()

# subjects who had more than 20 parcels showing extreme values. 
lower_threshold <- 
  working_df[,2:ncol(gordon333_cope11)] %>%
  map_dbl(~ quantile(., 0.25) - 1.5*IQR(.)) %>% unname()
upper_threshold <-  
  working_df[,2:ncol(gordon333_cope11)] %>%
  map_dbl(~ quantile(., 0.75) + 1.5*IQR(.)) %>% unname()

working_df_copy1 <-data.frame(working_df)
for (col in 2:ncol(gordon333_cope11)){
  working_df_copy1[,col] <- ifelse((working_df_copy1[,col] < lower_threshold[col-1]) | (working_df_copy1[,col] > upper_threshold[col-1]), 1, 0)
}

outlier_index_neural <- 
  working_df_copy1[,1:ncol(gordon333_cope11)] %>% 
  pivot_longer(., L_Auditory_ID10: R_Visual_ID311, names_to = "parcel_name",  values_to = "value") %>%
  filter(value == 1) %>%
  count(Subject) %>% 
  filter(n > 40)

# subjects who had extreme value in any of the behavioral measure.
lower_threshold <- 
  working_df[,(ncol(gordon333_cope11)+1):ncol(working_df)] %>%
  map_dbl(~ quantile(., 0.25) - 1.5*IQR(.)) %>% unname()
upper_threshold <-  
  working_df[,(ncol(gordon333_cope11)+1):ncol(working_df)] %>%
  map_dbl(~ quantile(., 0.75) + 1.5*IQR(.)) %>% unname()

working_df_copy2 <-data.frame(working_df)
for (col in (ncol(gordon333_cope11)+1):ncol(working_df)){
  working_df_copy2[,col] <- ifelse((working_df_copy2[,col] < lower_threshold[col-401]) | (working_df_copy2[,col] > upper_threshold[col-401]), 1, 0)
}

outlier_index_behavioral <- 
  working_df_copy2 %>% 
  select(Subject, WM_Task_2bk_Acc, ListSort_AgeAdj, PMAT24_A_CR, PicVocab_AgeAdj, ReadEng_AgeAdj) %>%
  pivot_longer(., WM_Task_2bk_Acc: ReadEng_AgeAdj, names_to = "parcel_name",  values_to = "value") %>%
  filter(value == 1) %>%
  count(Subject)

outlier_index_behavioral

# index the good subjects 
#good_sub <- working_df$Subject[!(working_df$Subject %in% outlier_index_neural$Subject)]
# rewrite the neural data: 
#gordon333_cope11 %>% 
#  filter(Subject %in% good_sub) %>%
#  write.csv(., file = "./data/gordon333_cope11_rm_outlier.csv", row.names = FALSE)
```

### Parcels have larger effect sizes
```{r parcel_es, warning = F}
rm(list = ls())

# load in the COPE11 data with Schaefer400 parcellation scheme applied:
gordon333_cope11 <- import(here::here('./data/gordon333_cope11_rm_outlier.csv')) %>%
  select(-Subject) # dont care about subject id here

# set up parameters: 
network_suffix <- c("Auditory","CinguloOperc","CinguloParietal","Default",
       "DorsalAttn","FrontoParietal","None","RetrosplenialTemporal",
       "Salience","SMhand","SMmouth","VentralAttn","Visual")
cohenD <- c() # Each parcel's load effect effect size
networks<- c() # Each parcel's network 
num <- c() # count the number of parcels in each network 
for (i in network_suffix) { # i <- 'Cont'
  num <- append(num, ncol(gordon333_cope11[,grep(i,colnames(gordon333_cope11))])) # number of parcels in each network
  cohenD <- append(cohenD, gordon333_cope11[,grep(i,colnames(gordon333_cope11))] %>%
                     map(~ (mean(.)/sd(.)))) # effect size for each parcel mean of the effect over sd of the data (Poldrack et al., 2017) 
  networks <- append(networks, rep(i,ncol(gordon333_cope11[,grep(i,colnames(gordon333_cope11))]))) # network names 
}

# create a data frame that has network and effect_size. 
info_table <- data.frame(array(data=NA, dim = c(333,2)))
colnames(info_table) <- c("network_name","effect_size")
info_table$effect_size <- as.numeric(cohenD)
info_table$network_name <- networks

# change the name for network for plotting purpose
for (i in 1: length(network_suffix)) {
  info_table$network_name <- gsub(pattern = network_suffix[i], replacement = paste0(network_suffix[i],"(",num[i],")"), x = info_table$network_name)
}

# get ready for plotting
colors = c("wheat1","darkorchid1","orange","cyan","blue","snow2","chartreuse1",
           "pink","black","aquamarine3","purple3","red","yellow") # match the color of the brain network
info_table %>%
  mutate( network_name = as.factor(info_table$network_name),
         network_name = reorder(info_table$network_name, info_table$effect_size, FUN = mean)) %>%
  ggplot(aes(network_name, effect_size)) + 
  geom_violin(fill = "gray") + 
  geom_boxplot(width = 0.2, fill = "white") +
  theme(legend.position = "none") +
  scale_y_continuous(breaks = c(-1,-0.5,0,0.5,1,1.5)) + 
  scale_x_discrete(limits=c("RetrosplenialTemporal(8)","Auditory(24)",
                            "SMmouth(8)","SMhand(38)","Visual(39)","None(47)",
                            "Default(41)","CinguloParietal(5)","VentralAttn(23)",
                            "CinguloOperc(40)","Salience(4)","DorsalAttn(32)","FrontoParietal(24)"
                            )) +
  coord_flip() +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
  annotate("text", x = 3, y = 1.1, label = "d = 0.8", color = "red") +
  theme_minimal() +
  theme(axis.title.x = element_text(size = 17, face ="bold"),
        axis.text.x = element_text(size = 13),
        axis.title.y = element_text(size = 17, face = "bold"),
        axis.text.y = element_text(size = 13,color = colors,face = "bold"), 
        plot.margin = margin(1,1,0,1,"cm")) +
  ylab("Effect Size") +
  xlab("Gordon Networks")

# Stats
info_table %>%
  mutate(network_name = as.factor(network_name)) %>%
  group_by(network_name) %>%
  summarize(mean_effect_size = mean(effect_size))

```

### Identification of WM-involved networks.
```{r distinct_network}
rm(list = ls())

# read in neural and behavioral data
gordon333_cope11 <- import(here::here('./data/gordon333_cope11_rm_outlier.csv'))
behavioral <- import(here::here('./data/HCP_behavioral_data.csv')) %>%
  select(Subject, WM_Task_2bk_Acc)
# join 
working_df <- inner_join(gordon333_cope11, behavioral, by = 'Subject') %>% 
  na.omit()

# ------------------------------------------------------------------------------
# to identify brain network that is sensitive to within-subject variations
# ------------------------------------------------------------------------------
# do a one sample t test for each parcel to identify within network
within_ttest <- 
  working_df %>%
  select(-c(Subject,WM_Task_2bk_Acc)) %>%
  map(~t.test(., mu = 0, alternative = "two.sided"))

# load activated parcel in the within network
load_activated_parcel_ttest <- 
  within_ttest[within_ttest %>% map(~.$statistic) > 0]
load_activated_parcel <- 
  load_activated_parcel_ttest[load_activated_parcel_ttest %>% map(~.$p.value) < 0.05/length(within_ttest)] %>%
  names()

# load deactivated parcel in the within network
load_deactivated_parcel_ttest <- 
  within_ttest[within_ttest %>% map(~ .$statistic) < 0]
load_deactivated_parcel <- 
  load_deactivated_parcel_ttest[load_deactivated_parcel_ttest %>% map(~.$p.value) < 0.05/length(within_ttest)] %>%
  names()

# load insensitive parcel 
load_insensitive_parcel <- colnames(gordon333_cope11)[-1][! colnames(gordon333_cope11)[-1] %in% c(load_activated_parcel,load_deactivated_parcel)]

# ------------------------------------------------------------------------------
# to identify brain network that is sensitive to between-subject variations
# ------------------------------------------------------------------------------

# parcels activation correlates with behavioral performance (between-network)
between_cortest_list <- 
  working_df %>%
  select(-c(Subject, WM_Task_2bk_Acc)) %>%
  map(~cor.test(., working_df$WM_Task_2bk_Acc))
  
# parcels that are positively correlated with behavior
beh_pos_cor_parcel_ttest <-
  between_cortest_list[between_cortest_list %>% map(~ magrittr::extract2(., 4)) > 0]
beh_pos_cor_parcel_name <-
  beh_pos_cor_parcel_ttest[beh_pos_cor_parcel_ttest %>% map(~ magrittr::extract2(., 3)) < 0.05/length(between_cortest_list)] %>%
  names()

# parcels that are negatively correlated with behavior
beh_neg_cor_parcel_ttest <-
  between_cortest_list[between_cortest_list %>% map(~ magrittr::extract2(., 4)) < 0]
beh_neg_cor_parcel_name <-
  beh_neg_cor_parcel_ttest[beh_neg_cor_parcel_ttest %>% map(~ magrittr::extract2(., 3)) < 0.05/length(between_cortest_list)] %>%
  names()

# --------------------------------------------------------
# Check the consistency of the directions of the effects. 
# --------------------------------------------------------
# out of 137 parcels exhibiting between-subjects WM effects, how many of them also 
# sensitive to within-subject difference? 
# n = 136
sum(c(beh_pos_cor_parcel_name,beh_neg_cor_parcel_name)  %in% c(load_activated_parcel, load_deactivated_parcel))
# out of 91 parcels showing positive behavioral correlation, how many are load-activated?
# n = 87
sum(beh_pos_cor_parcel_name %in% load_activated_parcel)
# out of 46 parcels showing negative behavioral correaltion, how many are load-deactivated?
# n = 46
sum(beh_neg_cor_parcel_name %in% load_deactivated_parcel)

```

### Parcels contribute to between and within-subject variations equivalently. 
```{r compare_es,warning=FALSE,message=FALSE}

# get cohenD and correlation coefficient ranking for every parcel: 
es_info <- data.frame(array(data=NA, dim = c(333,3)))
colnames(es_info) <- c('parcel_names','cohenD','coref') # colun names 
es_info$parcel_names <- colnames(working_df)[2:334] # parcel names 
es_info$cohenD <- working_df[,2:334] %>% map_dbl(~ (mean(.)/sd(.))) # compute cohen's D 
es_info$coref <- 
  working_df[,2:334] %>% 
  map_dbl(~ (cor.test(.,working_df$WM_Task_2bk_Acc)$estimate)) # compute correaltion with behavior. 

# rank the absolute values of the two effect sizes. 
es_info <- es_info %>%
  mutate(rank_cohenD = 334 - rank(abs(es_info$cohenD)),
         rank_coref = 334 - rank(abs(es_info$coref)),
         Parcel_type = ifelse(es_info$parcel_names %in% load_activated_parcel, 'Load-Activated', ifelse(es_info$parcel_names %in% load_deactivated_parcel, 'Load-Deactivated','Load-Insensitive')))

# get all parcels names in either load-activated network or between network, plot the two rank for these parcels
colors = c("red","blue","grey")
es_info %>%
  ggplot(aes(x = rank_cohenD, y = rank_coref, color = Parcel_type)) + 
  facet_grid(cols = vars(Parcel_type), scales = 'free') + 
  geom_point(alpha = 0.3) + 
  geom_smooth(method = 'lm', se = F) + 
  scale_color_manual(values = colors) + 
  theme_minimal() +
  theme(axis.title.x = element_text(size = 13, face ="bold"),
        axis.text.x = element_text(size = 10),
        axis.title.y = element_text(size = 13, face = "bold"),
        axis.text.y = element_text(size = 10, face = "bold"), 
        strip.text.x = element_text(size = 13, face = "bold"),
        plot.margin = margin(1,1,0,1,"cm"),
        legend.title = element_blank(),
        legend.position = 'None') +
  xlab("Within-subject effect rank \n(rank of |Cohen's d|)") +
  ylab("Between-subject effect rank \n(rank of |r|)")  

# --------------------------------------------------------------------------------------
# compute Spearman correlation coefficient of the rank orders of the two effect sizes. 
# for 3 functional groups separately. 
# --------------------------------------------------------------------------------------
within_between_es <- 
  es_info %>%
  group_by(Parcel_type) %>%
  nest() %>%
  mutate(cortest = map(data, ~ cor.test(.$rank_cohenD, .$rank_coref, data = ., method = "spearman")),
         estimate = map_dbl(cortest, ~ .$estimate),
         p_value = map_dbl(cortest, ~ .$p.value)) %>% 
  select(Parcel_type, estimate, p_value)
within_between_es

# -----------------------------------------
# z test for the correlation coefficients. 
# -----------------------------------------
parcel_count <- 
  es_info %>%
    group_by(Parcel_type) %>%
    summarize(count = n())
r_activated <- within_between_es$estimate[2]
n_activated <- parcel_count$count[1]
r_deactivated <- within_between_es$estimate[1]
n_deactivated <- parcel_count$count[2]

# is the coupling of the two effect sizes stronger for load-activated parcels? 
z_diff <- atanh(r_activated) - atanh(r_deactivated)
z_se <- ((1/(n_activated-3))+(1/(n_deactivated-3)))^0.5
2*(1-pnorm(z_diff/z_se))

#2. table
#3. cifti writing. 

```

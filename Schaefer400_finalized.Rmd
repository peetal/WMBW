---
title: "WMBW_Schaefer400"
output: html_document
---

```{r setup, include=FALSE, cache = TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r warning=FALSE,message=FALSE}
library(rio)
library(tidyverse)
library(sjmisc)
library(DescTools)
library(janitor)
library(magrittr)
library(doParallel)
library(kableExtra)
#library(Rmisc)
library(afex)
library(psych)
```

### Check and remove potential outliers (behavioral and neural)
```{r outlier_check}
rm(list = ls())

# load in the COPE11 data with Schaefer400 parcellation scheme applied:
schaefer400_cope11 <- import(here::here('./data/wm_schaf_cope11_pe_2mm_pe_400.csv'))
# load in behavioral results (2-back, list-sorting, Pmat, picVocalb, reading_recog)
behavioral <- import(here::here('./data/HCP_behavioral_data.csv')) %>%
  select(Subject, WM_Task_2bk_Acc, ListSort_AgeAdj, PMAT24_A_CR, PicVocab_AgeAdj, ReadEng_AgeAdj)
# merge and remove na
working_df <- inner_join(schaefer400_cope11, behavioral, by = 'Subject') %>% 
  na.omit()

# subjects who had more than 20 parcels showing extreme values. 
lower_threshold <- 
  working_df[,2:ncol(schaefer400_cope11)] %>%
  map_dbl(~ quantile(., 0.25) - 1.5*IQR(.)) %>% unname()
upper_threshold <-  
  working_df[,2:ncol(schaefer400_cope11)] %>%
  map_dbl(~ quantile(., 0.75) + 1.5*IQR(.)) %>% unname()

working_df_copy1 <-data.frame(working_df)
for (col in 2:ncol(schaefer400_cope11)){
  working_df_copy1[,col] <- ifelse((working_df_copy1[,col] < lower_threshold[col-1]) | (working_df_copy1[,col] > upper_threshold[col-1]), 1, 0)
}

outlier_index_neural <- 
  working_df_copy1[,1:ncol(schaefer400_cope11)] %>% 
  pivot_longer(., LH_Cont_Cing_1: RH_Vis_9, names_to = "parcel_name",  values_to = "value") %>%
  filter(value == 1) %>%
  count(Subject) %>% 
  filter(n > 40)

# subjects who had extreme value in any of the behavioral measure.
lower_threshold <- 
  working_df[,(ncol(schaefer400_cope11)+1):ncol(working_df)] %>%
  map_dbl(~ quantile(., 0.25) - 1.5*IQR(.)) %>% unname()
upper_threshold <-  
  working_df[,(ncol(schaefer400_cope11)+1):ncol(working_df)] %>%
  map_dbl(~ quantile(., 0.75) + 1.5*IQR(.)) %>% unname()

working_df_copy2 <-data.frame(working_df)
for (col in (ncol(schaefer400_cope11)+1):ncol(working_df)){
  working_df_copy2[,col] <- ifelse((working_df_copy2[,col] < lower_threshold[col-401]) | (working_df_copy2[,col] > upper_threshold[col-401]), 1, 0)
}

outlier_index_behavioral <- 
  working_df_copy2 %>% 
  select(Subject, WM_Task_2bk_Acc, ListSort_AgeAdj, PMAT24_A_CR, PicVocab_AgeAdj, ReadEng_AgeAdj) %>%
  pivot_longer(., WM_Task_2bk_Acc: ReadEng_AgeAdj, names_to = "parcel_name",  values_to = "value") %>%
  filter(value == 1) %>%
  count(Subject)

outlier_index_behavioral

# index the good subjects 
#good_sub <- working_df$Subject[!(working_df$Subject %in% outlier_index_neural$Subject)]
# rewrite the neural data: 
#schaefer400_cope11 %>% 
#  filter(Subject %in% good_sub) %>%
#  write.csv(., file = "./data/schaefer400_cope11_rm_outlier.csv", row.names = FALSE)
```

### Parcels have larger effect sizes
```{r parcel_es, warning = F}
rm(list = ls())

# load in the COPE11 data with Schaefer400 parcellation scheme applied:
schaefer400_cope11 <- import(here::here('./data/schaefer400_cope11_rm_outlier.csv')) %>%
  select(-Subject) # dont care about subject id here

# set up parameters: 
network_suffix <- c('Cont','Default','DorsAttn','Limbic','SalVentAttn','SomMot','Vis')
cohenD <- c() # Each parcel's load effect effect size
networks<- c() # Each parcel's network 
num <- c() # count the number of parcels in each network 
for (i in network_suffix) { # i <- 'Cont'
  num <- append(num, ncol(schaefer400_cope11[,grep(i,colnames(schaefer400_cope11))])) # number of parcels in each network
  cohenD <- append(cohenD, schaefer400_cope11[,grep(i,colnames(schaefer400_cope11))] %>%
                     map(~ (mean(.)/sd(.)))) # effect size for each parcel mean of the effect over sd of the data (Poldrack et al., 2017) 
  networks <- append(networks, rep(i,ncol(schaefer400_cope11[,grep(i,colnames(schaefer400_cope11))]))) # network names 
}

# create a data frame that has network and effect_size. 
info_table <- data.frame(array(data=NA, dim = c(400,2)))
colnames(info_table) <- c("network_name","effect_size")
info_table$effect_size <- as.numeric(cohenD)
info_table$network_name <- networks

# change the name for network for plotting purpose
for (i in 1: length(network_suffix)) {
  info_table$network_name <- gsub(pattern = network_suffix[i], replacement = paste0(network_suffix[i],"(",num[i],")"), x = info_table$network_name)
}

# get ready for plotting
colors = c("steelblue","moccasin","mediumorchid4","indianred3","purple3","springgreen4","tan2") # match the color of the brain network

info_table %>%
  mutate(network_name = as.factor(info_table$network_name),
         network_name = reorder(info_table$network_name, info_table$effect_size, FUN = mean)) %>%
  ggplot(aes(network_name, effect_size)) + 
  geom_violin(fill = "gray") + 
  geom_boxplot(width = 0.4, fill = "white") +
  #theme(legend.position = "right") +
  scale_y_continuous(breaks = c(-1,-0.5,0,0.5,1,1.5)) + 
  scale_x_discrete(limits=c("SomMot(77)","Limbic(26)",
                            "Vis(61)","Default(91)","SalVentAttn(47)","DorsAttn(46)",
                            "Cont(52)")) +
  coord_flip() +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
  annotate("text", x = 1, y = 1.1, label = "d = 0.8", color = "red") +
  theme_minimal() +
  theme(axis.title.x = element_text(size = 10, face ="bold"),
        axis.text.x = element_text(size = 10, face = "bold", margin = margin(t = 0, r = 0, b = 10, l = 0)),
        axis.title.y = element_text(size = 10, face = "bold", margin = margin(t = 0, r = 10, b = 0, l = 0)),
        axis.text.y = element_text(size = 10, color = colors,face = "bold"), 
        plot.margin = margin(0,1,0,1,"cm")) +
  ylab("Effect Size") +
  xlab("Schaefer 7 Networks") #+ 
  #xlab("") +
  #ggsave("plots/schaefer_parcel_es.svg", width=4.5, height=3)
  

# Stats
info_table %>%
  mutate(network_name = as.factor(network_name)) %>%
  group_by(network_name) %>%
  summarize(mean_effect_size = mean(effect_size), 
            sd_effect_size = sd(effect_size))

# percentage of parcels in the control network that show large effect sizes. 
big_es_parcel <- 
  info_table %>% 
    filter(network_name == "Cont(52)") %>% 
    mutate(big_es = ifelse(effect_size > 0.8, T, F)) %>% 
    select(big_es) %>%
    unname() %>% unlist() %>% sum()
big_es_parcel_percentage <- big_es_parcel/52

# percentage of parcels in the control network that show small effect sizes. 
small_es_parcel <- 
  info_table %>% 
    filter(network_name == "Cont(52)") %>% 
    mutate(big_es = ifelse(effect_size < 0.5, T, F)) %>% 
    select(big_es) %>%
    unname() %>% unlist() %>% sum()
small_es_parcel_percentage <- small_es_parcel/52
```

### Parcels have larger effect sizes: directly compare with vertex level efect size: 
```{r vertex_es, warning = F}

# # write a parcel_id csv like the one already made for Gordon
# schaefer400_id <- 
#   read.table("/Users/peetal/Documents/GitHub/WMBW/data/Schaefer400_7networks_parcel_order.txt")
# hem <- schaefer400_id$V2[-1] %>% 
#   map(~ unlist(str_split(., "_"))[1]) %>% unname() %>% unlist() # hemisphere
# community <- schaefer400_id$V2[-1] %>% 
#   map(~ unlist(str_split(., "_"))[2]) %>% unname() %>% unlist() # network
# 
# schaefer400_id_csv <- data.frame(array(NA, c(400, 3)))
# colnames(schaefer400_id_csv) <- c("ParcelID","Hem","Community")
# schaefer400_id_csv$ParcelID <- as.numeric(schaefer400_id$V1[-1]) + 1 # parcel id
# schaefer400_id_csv$Hem <- hem # hemisphere
# schaefer400_id_csv$Community <- community # network
# write.csv(schaefer400_id_csv, "/Users/peetal/Documents/Honor_project/Schaefer/Schaefer400_Parcels.csv", row.names = F)
# 
# -----------------------------------
# get vertex index for each network
# -----------------------------------
# rm(list=ls())
# 
# in_path <- "/Users/peetal/Documents/Honor_project/Schaefer2018_LocalGlobal/Parcellations/HCP/fslr32k/cifti/"
# out.path <- "/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/";
# g.key <- read.csv("/Users/peetal/Documents/Honor_project/Schaefer/Schaefer400_Parcels.csv", stringsAsFactors=FALSE); # which parcels in each community;
# setwd("/Users/peetal/Documents/Honor_project/workbench/bin_macosx64/")
# 
# # make a text version of the Gordon atlas - parcel assignment for each vertex
# dt.fname <- paste0(out.path, "Schaefer_Parcels_LR.dlabel.txt");
# if (!file.exists(dt.fname)) {
#   in.fname <- paste0(in_path, "Schaefer2018_400Parcels_7Networks_order.dlabel.nii");     # part of the Gordon atlas download
#   if (!file.exists(in.fname)) { stop(paste("missing:", in.fname)); }
#   system(paste0("./wb_command -cifti-convert -to-text ", in.fname, " ", dt.fname));   # call the  wb_command function
# }
# in.dt <- read.table(dt.fname)[,1];   # just one column in the file
# 
# 
# # each community has a different number of component parcels, and vertices in each parcel.
# # make a single file for each community listing *all* of its vertices.
# networks <- c("SomMot","Limbic","Vis","Default","SalVentAttn","DorsAttn")
# #networks <- c("Cont")
# for (do.comm in networks) {
#   for (do.hem in c("LH", "RH")) {   # do.comm <- "Vis"; do.hem <- "LH";
#     need.parcels <- g.key$ParcelID[which(g.key$Community == do.comm & g.key$Hem == do.hem)];  # parcels for this community & hemisphere
# 
#     # vertices (cifti rows) for each of these parcels
#     fout <- file(paste0(out.path, do.comm, "_", do.hem, "_ciftirows.txt"), 'wt');   # start a blank text file for writing
#     for (pid in 1:length(need.parcels)) {   # pid <- 1;
#       inds <- which(in.dt == need.parcels[pid]);   # rows of the cifti for parcel need.parcel[pid] only
#       for (i in 1:length(inds)) { cat(inds[i], file=fout, sep="\n"); }    # write out a line with each row number
#     }
#     close(fout); unlink(fout);    # let go of the file
#   }
# }
# 
# # -------------------------------------------------------------------------
# # get vertex level neural data (COPE11) for each subject, for each network
# # -------------------------------------------------------------------------
# 
# # important parameters
# in_path <- "/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/";   # _ciftirows.txt files, cope and id keys, etc.
# out_path <- "/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/";   # files written out to here
# comm_ids <- networks;
# hem_ids <- c("LH", "RH");
# 
# 
# # subject IDs
# ids <- import(here::here('./data/schaefer400_cope11_rm_outlier.csv')) %>%
#   select(Subject) %>% unname() %>% unlist()
# missing_id <- 0
# 
#  
# for (cid in 1:length(comm_ids)) { #for each network #cid = 1
#   if (!dir.exists(paste0(in_path, "Schaefer/",comm_ids[cid]))){ # if sub-folders for the network does not exist
#     dir.create(paste0(in_path, "Schaefer/",comm_ids[cid]))
#   }
#   for (sub in 1:length(ids)) { #for each subject #sub = 1
# 
#     lh_vertex_fname <- paste0(out_path, "cope11_vertex_dat_sur/", ids[sub], "_s1200_WMcope11s_L.txt")
#     rh_vertex_fname <- paste0(out_path, "cope11_vertex_dat_sur/", ids[sub], "_s1200_WMcope11s_R.txt")
#     if (!file.exists(lh_vertex_fname)) { missing_id <- missing_id + 1; next; }
# 
#     sub_L_R <- c()
#     for (hid in 1:length(hem_ids)) {   # for each hemisphere hid = 2;
#       # get the rows of the text-ized cifti for this community and hemisphere
#       fname <- paste0(in_path, "Schaefer/", comm_ids[cid], "_", hem_ids[hid], "_ciftirows.txt");
#       if (!file.exists(fname)) { stop(paste("missing:", fname)); }
#       need_rows <- read.table(fname)[,1];   # read in the file, just keeping the first column
#       if (hid ==2){need_rows <- need_rows - 32492 }
# 
#       # get COPE data:
#       if (hid == 1){ vertex <- read.table(lh_vertex_fname)[,1] }
#       if (hid == 2){ vertex <- read.table(rh_vertex_fname)[,1] }
#         
#       sub_L_R <- append(sub_L_R, vertex[need_rows])
#     }
# 
#     # write out data
#     sub_out_tbl <- array(NA, c(1, length(sub_L_R)));   # blank table to hold the values we need to keep
#     rownames(sub_out_tbl) <- "cope11";
#     colnames(sub_out_tbl) <- paste0("v", 1:length(sub_L_R));
#     sub_out_tbl[1,] <- sub_L_R
#     out_fname <- paste0(out_path, "Schaefer/", comm_ids[cid], "/", ids[sub], "_", comm_ids[cid], "_cope11s.txt")
#     write.table(sub_out_tbl, out_fname)
#   }
# }
# 
# # --------------------
# # compute effect size
# # --------------------
# 
# function that computes vertex level effect size for a given network
# vertex_level_es <- function(dir) { # dir <- "/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/Schaefer/SomMot/"
# 
#   data_from_dir <- Sys.glob(paste0(dir, '*.txt')) # all vertex within this network
#   nVertex <- ncol(read.table(data_from_dir[1])) # number of vertices in this network
#   nSub <- length(data_from_dir) # number of subjects
#   network_vertex_data <- data.frame(array(NA, c(nSub, nVertex + 1))) # create an empty dataframe
# 
#   for (i in 1:length(data_from_dir)){ # i = 1
# 
#     sub_id <- unlist(str_split(unlist(str_split(data_from_dir[i], "/"))[10],"_"))[1] # subject id
#     network_vertex_data[i,1] <- sub_id # add subject id to the dataframe
# 
#     #sub_data <- read.table(data_from_dir[i]) # extract in neural data
#     #network_vertex_data[i,1:nVertex + 1] <- sub_data[1,] %>% unname() %>% unlist() # extract in neural data
#     #print(i)
#   }
# 
#   # do it in parallel
#   cl <- parallel::makeCluster(8, setup_timeout = 0.5)
#   registerDoParallel(cl)
#   all_data <-
#     data_from_dir %>%
#       map(~ read.table(.)[1,] %>% unname() %>% unlist())
#   stopCluster(cl)
#   registerDoSEQ()
# 
#   for (i in 1:length(all_data)){
#     network_vertex_data[i,1:nVertex + 1] <- all_data[[i]]
#   }
# 
#   # compute load effect size for all the vertices
#   cohenD <- network_vertex_data %>%
#     select(-X1) %>%
#     map_dbl(~ (mean(.)/sd(.))) # effect size for each parcel mean of the effect over sd of the data (Poldrack et al., 2017)
# 
#   return(cohenD)
# }
# 
# cont_es <- vertex_level_es("/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/Schaefer/Cont/")
# dorsAttn_es <- vertex_level_es("/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/Schaefer/DorsAttn/")
# salVentAttn_es <- vertex_level_es("/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/Schaefer/SalVentAttn/")
# default_es <- vertex_level_es("/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/Schaefer/Default/")
# vis_es <- vertex_level_es("/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/Schaefer/Vis/")
# limbic_es <- vertex_level_es("/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/Schaefer/Limbic/")
# somMot_es <- vertex_level_es("/Users/peetal/Documents/Honor_project/Schaefer/vertex_level_data/Schaefer/SomMot/")
# 
# df <- data.frame(network  = c(rep("Cont", length(cont_es)),
#                               rep("Limbic", length(limbic_es)),
#                               rep("Vis", length(vis_es)),
#                               rep("Default", length(default_es)),
#                               rep("SalVentAttn", length(salVentAttn_es)),
#                               rep("DorsAttn", length(dorsAttn_es)),
#                               rep("SomMot", length(somMot_es))),
#                    es = c(cont_es, limbic_es,  vis_es, default_es, salVentAttn_es, dorsAttn_es, somMot_es))
# write.csv(schaefer_vertex,"/Users/peetal/Documents/GitHub/WMBW/data/Schaefer_vertex_es.csv", row.names = F)
#  
schaefer_vertex <- import(here::here("data/Schaefer_vertex_es.csv")) 

# get ready for plotting
colors = c("steelblue","moccasin","mediumorchid4","indianred3","purple3","springgreen4","tan2") # match the color of the brain network

schaefer_vertex %>%
  mutate(network = as.factor(schaefer_vertex$network),
         network= reorder(schaefer_vertex$network, schaefer_vertex$es, FUN = mean)) %>%
  ggplot(aes(network, es)) + 
  geom_violin(fill = "gray") + 
  geom_boxplot(width = 0.4, fill = "white") +
  #theme(legend.position = "right") +
  scale_y_continuous(breaks = c(-1,-0.5,0,0.5,1,1.5)) + 
  scale_x_discrete(limits=c("SomMot","Limbic","Vis","Default",
                            "SalVentAttn","DorsAttn","Cont")) +
  ylim(-1,1.5) +
  coord_flip() +
  geom_hline(yintercept = 0.8, linetype = "dashed", color = "red") +
  annotate("text", x = 1, y = 1.1, label = "d = 0.8", color = "red") +
  theme_minimal() +
  theme(axis.title.x = element_text(size = 10, face ="bold"),
        axis.text.x = element_text(size = 10, face = "bold", margin = margin(t = 0, r = 0, b = 10, l = 0)),
        axis.title.y = element_text(size = 10, face = "bold", margin = margin(t = 0, r = 10, b = 0, l = 0)),
        axis.text.y = element_text(size = 10, color = colors,face = "bold"), 
        plot.margin = margin(0,1,0,1,"cm")) +
  ylab("Effect Size") +
  xlab("Schaefer 7 Networks") #+ 
  #xlab("") +
  #ggsave("plots/schaefer_vertex_es.svg", width=4.5, height=3)

# Stats
schaefer_vertex %>%
  mutate(network = as.factor(network)) %>%
  group_by(network) %>%
  summarize(mean_effect_size = mean(es),
            sd_effect_size = sd(es))

# percentage of vertex in the control network that show large effect sizes. 
big_es_vertex <- 
  schaefer_vertex %>% 
    filter(network == "Cont") %>% 
    mutate(big_es = ifelse(es > 0.8, T, F)) %>% 
    select(big_es) %>%
    unname() %>% unlist() %>% sum()
big_es_vertex_percentage <- big_es_vertex/6907
  
# percentage of vertex in the control network that show small effect sizes. 
small_es_vertex <- 
  schaefer_vertex %>% 
    filter(network == "Cont") %>% 
    mutate(big_es = ifelse(es < 0.5, T, F)) %>% 
    select(big_es) %>%
    unname() %>% unlist() %>% sum()
small_es_vertex_percentage <- small_es_vertex/6907
  


```


### Identification of WM-involved networks.
```{r distinct_network}
rm(list = ls())

# read in neural and behavioral data
schaefer400_cope11 <- import(here::here('./data/schaefer400_cope11_rm_outlier.csv'))
behavioral <- import(here::here('./data/HCP_behavioral_data.csv')) %>%
  select(Subject, WM_Task_2bk_Acc)
# join 
working_df <- inner_join(schaefer400_cope11, behavioral, by = 'Subject') %>% 
  na.omit()

# ------------------------------------------------------------------------------
# to identify brain network that is sensitive to within-subject variations
# ------------------------------------------------------------------------------
# do a one sample t test for each parcel to identify within network
within_ttest <- 
  working_df %>%
  select(-c(Subject,WM_Task_2bk_Acc)) %>%
  map(~t.test(., mu = 0, alternative = "two.sided"))

# load activated parcel in the within network
load_activated_parcel_ttest <- 
  within_ttest[within_ttest %>% map(~.$statistic) > 0]
load_activated_parcel <- 
  load_activated_parcel_ttest[load_activated_parcel_ttest %>% map(~.$p.value) < 0.05/length(within_ttest)] %>%
  names()

# load deactivated parcel in the within network
load_deactivated_parcel_ttest <- 
  within_ttest[within_ttest %>% map(~ .$statistic) < 0]
load_deactivated_parcel <- 
  load_deactivated_parcel_ttest[load_deactivated_parcel_ttest %>% map(~.$p.value) < 0.05/length(within_ttest)] %>%
  names()

# load insensitive parcel 
load_insensitive_parcel <- colnames(schaefer400_cope11)[-1][! colnames(schaefer400_cope11)[-1] %in% c(load_activated_parcel,load_deactivated_parcel)]

# ------------------------------------------------------------------------------
# to identify brain network that is sensitive to between-subject variations
# ------------------------------------------------------------------------------

# parcels activation correlates with behavioral performance (between-network)
between_cortest_list <- 
  working_df %>%
  select(-c(Subject, WM_Task_2bk_Acc)) %>%
  map(~cor.test(., working_df$WM_Task_2bk_Acc))
  
# parcels that are positively correlated with behavior
beh_pos_cor_parcel_ttest <-
  between_cortest_list[between_cortest_list %>% map(~ magrittr::extract2(., 4)) > 0]
beh_pos_cor_parcel_name <-
  beh_pos_cor_parcel_ttest[beh_pos_cor_parcel_ttest %>% map(~ magrittr::extract2(., 3)) < 0.05/length(between_cortest_list)] %>%
  names()

# parcels that are negatively correlated with behavior
beh_neg_cor_parcel_ttest <-
  between_cortest_list[between_cortest_list %>% map(~ magrittr::extract2(., 4)) < 0]
beh_neg_cor_parcel_name <-
  beh_neg_cor_parcel_ttest[beh_neg_cor_parcel_ttest %>% map(~ magrittr::extract2(., 3)) < 0.05/length(between_cortest_list)] %>%
  names()

# --------------------------------------------------------
# Check the consistency of the directions of the effects. 
# --------------------------------------------------------
# out of 177 parcels exhibiting between-subjects WM effects, how many of them also 
# sensitive to within-subject difference? 
# n = 175
sum(c(beh_pos_cor_parcel_name,beh_neg_cor_parcel_name)  %in% c(load_activated_parcel, load_deactivated_parcel))
# out of 120 parcels showing positive behavioral correlation, how many are load-activated?
# n = 113
sum(beh_pos_cor_parcel_name %in% load_activated_parcel)
# out of 57 parcels showing negative behavioral correaltion, how many are load-deactivated?
# n = 57
sum(beh_neg_cor_parcel_name %in% load_deactivated_parcel)

```

### Parcels contribute to between and within-subject variations equivalently. 
```{r compare_es,warning=FALSE,message=FALSE}

# get cohenD and correlation coefficient ranking for every parcel: 
es_info <- data.frame(array(data=NA, dim = c(400,3)))
colnames(es_info) <- c('parcel_names','cohenD','coref') # colun names 
es_info$parcel_names <- colnames(working_df)[2:401] # parcel names 
es_info$cohenD <- working_df[,2:401] %>% map_dbl(~ (mean(.)/sd(.))) # compute cohen's D 
es_info$coref <- 
  working_df[,2:401] %>% 
  map_dbl(~ (cor.test(.,working_df$WM_Task_2bk_Acc)$estimate)) # compute correaltion with behavior. 

# rank the absolute values of the two effect sizes. 
es_info <- es_info %>%
  mutate(rank_cohenD = 401 - rank(abs(es_info$cohenD)),
         rank_coref = 401 - rank(abs(es_info$coref)),
         Parcel_type = ifelse(es_info$parcel_names %in% load_activated_parcel, 'Activated', ifelse(es_info$parcel_names %in% load_deactivated_parcel, 'Deactivated','Insensitive')))

# get all parcels names in either load-activated network or between network, plot the two rank for these parcels
colors = c("red","blue","grey")
es_info %>%
  ggplot(aes(x = rank_cohenD, y = rank_coref, color = Parcel_type)) + 
  facet_grid(cols = vars(Parcel_type), scales = 'free') + 
  geom_point(alpha = 0.3) + 
  geom_smooth(method = 'lm', se = F) + 
  scale_color_manual(values = colors) + 
  theme_minimal() +
  theme(axis.title.x = element_text(size = 10),
        axis.text.x = element_text(size = 6),
        axis.title.y = element_text(size = 10),
        axis.text.y = element_text(size = 6), 
        strip.text.x = element_text(size = 8),
        plot.margin = margin(0,0,0,0,"cm"),
        legend.title = element_blank(),
        legend.position = 'None') +
  xlab("Within-subject effect rank \n(rank of |Cohen's d|)") +
  ylab("Between-subject effect rank \n(rank of |r|)")  # + 
  #ggsave("plots/rank_cor.svg", width=3.3, height=2.8)

# --------------------------------------------------------------------------------------
# compute Spearman correlation coefficient of the rank orders of the two effect sizes. 
# for 3 functional groups separately. 
# --------------------------------------------------------------------------------------
within_between_es <- 
  es_info %>%
  group_by(Parcel_type) %>%
  nest() %>%
  mutate(cortest = map(data, ~ cor.test(.$rank_cohenD, .$rank_coref, data = ., method = "spearman")),
         estimate = map_dbl(cortest, ~ .$estimate),
         p_value = map_dbl(cortest, ~ .$p.value)) %>% 
  select(Parcel_type, estimate, p_value)
within_between_es

# -----------------------------------------
# z test for the correlation coefficients. 
# -----------------------------------------
parcel_count <- 
  es_info %>%
    group_by(Parcel_type) %>%
    summarize(count = n())
r_activated <- within_between_es$estimate[2]
n_activated <- parcel_count$count[1]
r_deactivated <- within_between_es$estimate[3]
n_deactivated <- parcel_count$count[2]

# is the coupling of the two effect sizes stronger for load-activated parcels? 
r.test(n = n_activated, r12 = r_activated, r34 = r_deactivated, n2 = n_deactivated)

# ----------------------------------------------------------------
# Descriptive stats for individual difference sensitive parcels
# ----------------------------------------------------------------
es_info %>% filter(parcel_names %in% beh_pos_cor_parcel_name) %>%select(coref) %>% describe(.)
es_info %>% filter(parcel_names %in% beh_neg_cor_parcel_name) %>%select(coref) %>% describe(.)

```
### Load-effect sizes indicates parcelâ€™s univariate predictive power
```{r}
# -----------------------------------------------------------------------------
# Relationship between load-related effect size and univariate predictive power 
# -----------------------------------------------------------------------------
# univariate pred acc:
schaefer_uni_pred_acc <- import(here::here('data/univariate_pred_acc/schaefer_univariate_pred_acc_all_parcel.csv')) %>%
  rename(parcel_names = parcel_name) %>%
  select(parcel_names, pred_wm) 
  
# top and bottom 30 load-act parcels
es_info2_load_act <- inner_join(schaefer_uni_pred_acc, es_info, by="parcel_names") %>% 
  filter(Parcel_type == "Activated") %>%
  arrange(desc(cohenD))

load_act_tail_30 <- 
  es_info2_load_act %>% top_n(30, rank_cohenD) %>% select(parcel_names) %>% unname() %>% unlist() %>% as.vector()
load_act_head_30 <- 
  es_info2_load_act %>% top_n(-30, rank_cohenD) %>% select(parcel_names) %>% unname() %>% unlist() %>% as.vector()
es_info2_load_act <- es_info2_load_act %>%
  filter(parcel_names %in% c(load_act_tail_30, load_act_head_30))
parcel_act_order <- c(load_act_head_30, rep(" ",5), load_act_tail_30)
  
# top and bottom 30 load-deact parcels
es_info2_load_deact <- inner_join(schaefer_uni_pred_acc, es_info, by="parcel_names") %>% 
  filter(Parcel_type == "Deactivated") %>% 
  arrange(cohenD)

load_deact_tail_30 <- 
  es_info2_load_deact %>% top_n(30, rank_cohenD) %>% select(parcel_names) %>% unname() %>% unlist() %>% as.vector()
load_deact_head_30 <- 
  es_info2_load_deact %>% top_n(-30, rank_cohenD) %>% select(parcel_names) %>% unname() %>% unlist() %>% as.vector()
es_info2_load_deact <- es_info2_load_deact %>%
  filter(parcel_names %in% c(load_deact_tail_30, load_deact_head_30))
parcel_deact_order <- c(load_deact_head_30, rep(" ",5), load_deact_tail_30)


es_info2_load_act %>%
  mutate(parcel_names = factor(parcel_names)) %>%
  ggplot(aes(x = parcel_names, y = pred_wm)) + 
  geom_bar(aes(fill = Parcel_type), stat='identity') + 
  theme_classic() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y = element_text(size = 10, face = "bold"),
        axis.text.y = element_text(size = 8, face = "bold"), 
        axis.title.x = element_text(size = 10, face = "bold"),
        plot.margin = margin(0,0,0,0,"cm"),
        legend.title = element_blank(),
        legend.position = 'None') +
  scale_x_discrete(limits=parcel_act_order) +
  ylim(-0.12,0.5) + 
  ylab("Predictive power") + 
  xlab("Cohen's d") #+ 
  #ggsave("plots/load_act_univariate.svg", width=3.3, height=1.9)


# correlation between cohenD and univariate predictive power 
cor.test(es_info2_load_act$cohenD, es_info2_load_act$pred_wm)
# mean cohenD and mean univariate predictive power for top and bottom 20 parcels
es_info2_load_act %>%
  filter(rank_cohenD < 40) %>%
  mutate(mean_cohend = mean(cohenD),
         mean_pred_wm = mean(pred_wm)) %>%
  select(mean_cohend, mean_pred_wm) %>% unique()
es_info2_load_act %>%
  filter(rank_cohenD > 40) %>%
  mutate(mean_cohend = mean(cohenD),
         mean_pred_wm = mean(pred_wm)) %>%
  select(mean_cohend, mean_pred_wm) %>% unique()

es_info2_load_deact %>%
  mutate(parcel_names = factor(parcel_names)) %>%
  ggplot(aes(x = parcel_names, y = pred_wm)) + 
  geom_bar(aes(fill = Parcel_type), stat='identity', fill = "dodgerblue3") + 
  theme_classic() +
  theme(axis.title.y = element_text(size = 10, face = "bold"),
        axis.title.x = element_text(size = 10, face = "bold"),
        axis.text.y = element_text(size = 8, face = "bold"), 
        axis.text.x=element_blank(),
        axis.ticks.x = element_blank(),
        plot.margin = margin(0,0,0,0,"cm"),
        legend.title = element_blank(),
        legend.position = 'None') +
  scale_x_discrete(limits=parcel_deact_order) +
  ylim(-0.12,0.5) + 
  ylab("Predictive power") + 
  xlab("Cohen's d") #+ 
  #ggsave("plots/load_deact_univariate.svg", width=3.3, height=1.9)

# get some stats 
# correlation between cohenD and univariate predictive power 
cor.test(es_info2_load_deact$cohenD, es_info2_load_deact$pred_wm)
# mean cohenD and mean univariate predictive power for top and bottom 20 parcels
es_info2_load_deact %>%
  filter(rank_cohenD < 40) %>%
  mutate(mean_cohend = mean(cohenD),
         mean_pred_wm = mean(pred_wm)) %>%
  select(mean_cohend, mean_pred_wm) %>% unique()
es_info2_load_deact %>%
  filter(rank_cohenD > 40) %>%
  mutate(mean_cohend = mean(cohenD),
         mean_pred_wm = mean(pred_wm)) %>%
  select(mean_cohend, mean_pred_wm) %>% unique()

```

### Generating Table1
```{r}
table <- es_info[order(es_info$rank_cohenD),][1:50,] %>%
  select(parcel_names, cohenD)
# add univariate predictive acc
univariate <- import(here::here('data/univariate_pred_acc/schaefer_univariate_pred_acc.csv'))
table$pred_wm_acc <- univariate$pred_wm
# add pracel id 
schaefer_order_txt <- import(here::here('data/Schaefer400_7networks_parcel_order.txt'))
for (row in 1:nrow(table)){
  table$shaefer_id[row] <- schaefer_order_txt$order[which(schaefer_order_txt$parcel_name == table$parcel_names[row])]
}

# dataframe into table 
rownames(table) <- NULL
colnames(table) <- c("Parcel Name", "Load-effect Size", "Univariate predictive accuracy for 2-back performance", "Schaefer ID" )
table <- table[c("Parcel Name", "Schaefer ID", "Load-effect Size", "Univariate predictive accuracy for 2-back performance")]
table %>%
  kbl(booktabs = T, align = "c") %>%
  kable_classic_2(full_width = F) %>%
  column_spec(., 4, width = "5cm")
```

### Write CIFTI for plotting neural correlates
```{r}
source('/Users/peetal/Documents/Honor_project/Schaefer/func/write_schaefer400_7N_cifti.R') 
#  load in order
schaefer_order_txt <- import(here::here('data/Schaefer400_7networks_parcel_order.txt'))

# ---------------------------
# within-subject effect size 
# ---------------------------
outvec <- c()
for (i in schaefer_order_txt$parcel_name){ # i = 'LH_Vis_1'
  if (i %in% c(load_activated_parcel, load_deactivated_parcel)){
    outvec <- append(outvec, es_info$cohenD[which(es_info$parcel_names == i)])
  } else{
    outvec <- append(outvec, 0)
  }
}
#write.table(outvec, '/Users/peetal/Documents/Honor_project/Schaefer/working/schaefer400/outvec_txt/schaefer_within_subject_effect.txt', col.names=FALSE,row.names=FALSE)
#write_schaefer400_pscalar('schaefer_within_subject_effect.txt', 'schaefer_within_subject_effect.pscalar.nii')

# -----------------------------
# between-subject effects size 
# -----------------------------
outvec <- c()
for (i in schaefer_order_txt$parcel_name){ # i = 'LH_Vis_1'
  if (i %in% c(beh_pos_cor_parcel_name, beh_neg_cor_parcel_name)){
    outvec <- append(outvec, es_info$coref[which(es_info$parcel_names == i)])
  } else{
    outvec <- append(outvec, 0)
  }
}
#write.table(outvec, '/Users/peetal/Documents/Honor_project/Schaefer/working/schaefer400/outvec_txt/schaefer_between_subject_effect.txt', col.names=FALSE,row.names=FALSE)
#write_schaefer400_pscalar('schaefer_between_subject_effect.txt', 'schaefer_between_subject_effect.pscalar.nii')

# ----------------------------------
# spatial distribution of rank diff
# ----------------------------------
es_info <-  es_info %>%
  mutate(rank_diff = rank_coref - rank_cohenD) %>%
  mutate(rank_diff = scale(rank_diff))

outvec <- c()
for (i in schaefer_order_txt$parcel_name){ # i = 'LH_Vis_1'
  outvec <- append(outvec,es_info[which(es_info$parcel_names == i),]$rank_diff)
}

#write.table(outvec, '/Users/peetal/Documents/Honor_project/Schaefer/working/schaefer400/outvec_txt/schaefer_parcels_es_diff.txt', col.names=FALSE,row.names=FALSE)
#write_schaefer400_pscalar('schaefer_parcels_es_diff.txt', 'schaefer_parcels_es_diff.pscalar.nii')


# ---------------
# top 30 parcels: 
# ---------------
top_30_parcels <- es_info[order(es_info$rank_cohenD),][1:30,] %>% select(parcel_names) %>% unlist() %>% unname()
top_5_parcels <- top_30_parcels[1:5]

outvec <- c()
for (i in schaefer_order_txt$parcel_name){ # i = 'LH_Vis_1'
  if (i %in% top_30_parcels){
    if (i %in% top_5_parcels){
      outvec <- append(outvec,2)
    } else {
      outvec <- append(outvec,1)
    }
  } else{
    outvec <- append(outvec,0)
  }
}

write.table(outvec, '/Users/peetal/Documents/Honor_project/Schaefer/working/schaefer400/outvec_txt/schaefer_top_30.txt', col.names=FALSE,row.names=FALSE)
write_schaefer400_pscalar('schaefer_top_30.txt', 'schaefer_top_30.pscalar.nii')

```

### Load-effect sizes indicates parcel's predictive power
```{r nested_permutation}
rm(list = ls())
# plotting for predictive power per parcel bins: 
plot_pred_acc_bin <- function(df_name, measure){
  # load dataframe
  df_inscanner <- import(here::here(paste0("data/schaefer_permutation/",df_name)))
  # select real_data
  real_data <- 
    df_inscanner[1,] %>% 
    pivot_longer(., -load_insensitive, names_to = c("parcel_type","effect_size"), 
                 values_to = "pred_acc", names_pattern = "(.*)_(.*_.*)" ) %>%
    mutate(parcel_type = ifelse(parcel_type == "act", "Activated", "Deactivated"))
  # plotting 
  real_data %>% 
    ggplot(aes(x = effect_size, y = pred_acc, color = parcel_type)) +
    geom_point(size = 0.8) + 
    geom_line(aes(group = parcel_type, color = parcel_type)) + 
    geom_hline(yintercept = df_inscanner$load_insensitive[1], color = "gray", linetype = "dashed") + 
    ylim(0, df_inscanner$act_13_15[1] + 0.1) + 
    xlab("") + 
    ylab("Predictive Acc") + 
    ggtitle(paste0(measure)) + 
    scale_x_discrete(labels=c("01_03" = "(0.1,0.3)", "03_05" = "(0.3,0.5)", "05_07" = "(0.5,0.7)", 
                              "07_09" = "(0.7,0.9)", "09_11" = "(0.9,1.1)", "11_13" = "(1.1,1.3)",
                              "13_15" = "(1.3,1.5)")) + 
    theme_classic() +
    theme(axis.title.x = element_text(size = 10),
          axis.text.x = element_text(size = 6),
          axis.title.y = element_text(size = 10),
          axis.text.y = element_text(size = 8), 
          plot.title = element_text(size = 10, hjust = 0.5, face = "bold"),
          plot.margin = margin(0,0,0,0,"cm"),
          legend.position = c(0.2, 0.8)) #+ 
    #ggsave(paste0("plots/multivariate_",measure,".svg"), width=3.3, height=1.9)
}

# linear trend statistical test: 
linear_trend_stats <- function(df_name){ #df_name = "schaefer_nested_permutation_test_12bin_WM_Task_2bk_Acc.csv"
  df <- import(here::here(paste0("data/schaefer_permutation/",df_name)))
  # select real_data
  real_data <- 
    df[1,] %>% 
    pivot_longer(., -load_insensitive, names_to = c("parcel_type","effect_size"), 
                 values_to = "pred_acc", names_pattern = "(.*)_(.*_.*)" ) %>%
    mutate(parcel_type = ifelse(parcel_type == "act", "Activated", "Deactivated"))
  # linear trend for activated
  act_real_lt <- real_data %>%
    filter(parcel_type == "Activated") %>%
    mutate(effect_size_rank = c(1,2,3,4,5,6,7)) %>%
    lm(pred_acc ~ effect_size_rank, .) %>% 
    summary()
  # linear trend for deactivated
  deact_real_lt <- real_data %>% 
    filter(parcel_type == "Deactivated") %>%
    mutate(effect_size_rank = c(1,2,3,4)) %>% 
    lm(pred_acc ~ effect_size_rank, .) %>% 
    summary()
  # null linear trend coefficient for activated bins
  null_coef_act <- c()
  for (row in 2:1001){
    mat <- matrix(c(as.numeric(df[row,1:7]), c(1,2,3,4,5,6,7)), ncol = 2)
    null_lt <- lm(mat[,1]~ mat[,2]) %>% summary()
    null_coef_act <- append(null_coef_act, null_lt$coefficients[2,1])
  }
  # null linear trend coefficient for deactivated bins
  null_coef_deact <- c()
  for (row in 2:1001){
    mat <- matrix(c(as.numeric(df[row,8:11]), c(1,2,3,4)), ncol = 2)
    null_lt <- lm(mat[,1]~ mat[,2]) %>% summary()
    null_coef_deact <- append(null_coef_deact, null_lt$coefficients[2,1])
  }
  # compute p-values for the observed linear trend coefficients. 
  act_real_lt_p <- (1- pnorm((act_real_lt$coefficients[2,1] - mean(null_coef_act))/sd(null_coef_act)))*2
  deact_real_lt_p <- (1- pnorm((deact_real_lt$coefficients[2,1] - mean(null_coef_deact))/sd(null_coef_deact)))*2
  
  print(paste0("Act linear trend coefficient is ", act_real_lt$coefficients[2,1], "and its P values is ", act_real_lt_p))
  print(paste0("Deact linear trend coefficient is ", deact_real_lt$coefficients[2,1], "and its P values is ", deact_real_lt_p))
}

# compare load-activated and load-deactivated parcels given the same effect size. 
compare_pred_acc_bins <- function(df_name){ # df_name = "schaefer_nested_permutation_test_12bin_WM_Task_2bk_Acc.csv"
  
  # load data 
  df <- import(here::here(paste0("data/schaefer_permutation/",df_name)))
  # extract bins to be compared with 
  real <- data.frame("activated" = as.numeric(df[1,1:4]),
                     "deactivated" = as.numeric(df[1,8:11]),
                     "insensitive" = rep(as.numeric(df[1,12]), 4)) %>%
    mutate(act_minus_deactivated = activated - deactivated,
           deactivated_minus_insensitive = deactivated - insensitive,
           activated_minus_insensitive = activated - insensitive) %>%
    select(act_minus_deactivated, deactivated_minus_insensitive, activated_minus_insensitive)
  
  # build null distribution
  null_01_03 <- c()
  null_03_05 <- c()
  null_05_07 <- c()
  null_07_09 <- c()
  for (row in 2:1001){ # row = 2
      mat <- data.frame("activated" = as.numeric(df[row,1:4]),
                         "deactivated" = as.numeric(df[row,8:11]),
                         "insensitive" = rep(as.numeric(df[row,12]), 4)) %>%
        mutate(act_minus_deactivated = activated - deactivated,
               deactivated_minus_insensitive = deactivated - insensitive,
               activated_minus_insensitive = activated - insensitive) %>%
        select(act_minus_deactivated, deactivated_minus_insensitive, activated_minus_insensitive)
      # build null distribution for the differences of load-activated and deactivated bins
      null_01_03 <- append(null_01_03, mat$act_minus_deactivated[1])
      null_03_05 <- append(null_03_05, mat$act_minus_deactivated[2])
      null_05_07 <- append(null_05_07, mat$act_minus_deactivated[3])
      null_07_09 <- append(null_07_09, mat$act_minus_deactivated[4])
  } 
  
  
  # compute p values: 
  p_01_03 <- (1- pnorm(abs(real$act_minus_deactivated[1] - mean(null_01_03))/sd(null_01_03)))*2
  p_03_05 <- (1- pnorm(abs(real$act_minus_deactivated[2] - mean(null_03_05))/sd(null_03_05)))*2
  p_05_07 <- (1- pnorm(abs(real$act_minus_deactivated[3] - mean(null_05_07))/sd(null_05_07)))*2
  p_07_09 <- (1- pnorm(abs(real$act_minus_deactivated[4] - mean(null_07_09))/sd(null_07_09)))*2

  print(paste0("Difference in bin 01_03 is ", real$act_minus_deactivated[1], "P value is ",  p_01_03))
  print(paste0("Difference in bin 03_05 is ", real$act_minus_deactivated[2], "P value is ",  p_03_05))
  print(paste0("Difference in bin 05_07 is ", real$act_minus_deactivated[3], "P value is ",  p_05_07))
  print(paste0("Difference in bin 07_09 is ", real$act_minus_deactivated[4], "P value is ",  p_07_09))
  
}


# WM_Task_2bk_Acc
plot_pred_acc_bin("schaefer_nested_permutation_test_12bin_WM_Task_2bk_Acc.csv", "2-back Task")
linear_trend_stats("schaefer_nested_permutation_test_12bin_WM_Task_2bk_Acc.csv")
compare_pred_acc_bins("schaefer_nested_permutation_test_12bin_WM_Task_2bk_Acc.csv")

# PicVocab_AgeAdj
plot_pred_acc_bin("schaefer_nested_permutation_test_12bin_PicVocab_AgeAdj.csv", "Pic-vocab Task")
linear_trend_stats("schaefer_nested_permutation_test_12bin_PicVocab_AgeAdj.csv")
compare_pred_acc_bins("schaefer_nested_permutation_test_12bin_PicVocab_AgeAdj.csv")

# PMAT24_A_CR
plot_pred_acc_bin("schaefer_nested_permutation_test_12bin_PMAT24_A_CR.csv", "PMAT Task")
linear_trend_stats("schaefer_nested_permutation_test_12bin_PMAT24_A_CR.csv")
compare_pred_acc_bins("schaefer_nested_permutation_test_12bin_PMAT24_A_CR.csv")

# ReadEng_AgeAdj
plot_pred_acc_bin("schaefer_nested_permutation_test_12bin_ReadEng_AgeAdj.csv", "Reading-cog Task")
linear_trend_stats("schaefer_nested_permutation_test_12bin_ReadEng_AgeAdj.csv")
compare_pred_acc_bins("schaefer_nested_permutation_test_12bin_ReadEng_AgeAdj.csv")

# ListSort_AgeAdj
plot_pred_acc_bin("schaefer_nested_permutation_test_12bin_ListSort_AgeAdj.csv", "List-Sorting Task")
linear_trend_stats("schaefer_nested_permutation_test_12bin_ListSort_AgeAdj.csv")
compare_pred_acc_bins("schaefer_nested_permutation_test_12bin_ListSort_AgeAdj.csv")
```
# for supplementary figures
```{r}
rm(list = ls())

df_vocab <- import(here::here("data/schaefer_permutation/schaefer_nested_permutation_test_12bin_PicVocab_AgeAdj.csv"))[1,] %>%
  pivot_longer(., -load_insensitive, names_to = c("parcel_type","effect_size"), 
               values_to = "pred_acc", names_pattern = "(.*)_(.*_.*)" ) %>%
  mutate(parcel_type = ifelse(parcel_type == "act", "Activated", "Reverse-Activated"),
         condition = rep("Vocab Task", nrow(.))) %>%
  select(-load_insensitive)

df_pmat <- import(here::here("data/schaefer_permutation/schaefer_nested_permutation_test_12bin_PMAT24_A_CR.csv"))[1,] %>%
  pivot_longer(., -load_insensitive, names_to = c("parcel_type","effect_size"), 
               values_to = "pred_acc", names_pattern = "(.*)_(.*_.*)" ) %>%
  mutate(parcel_type = ifelse(parcel_type == "act", "Activated", "Reverse-Activated"),
         condition = rep("PMAT Task", nrow(.))) %>%
  select(-load_insensitive)

df_reading <- import(here::here("data/schaefer_permutation/schaefer_nested_permutation_test_12bin_ReadEng_AgeAdj.csv"))[1,] %>%
  pivot_longer(., -load_insensitive, names_to = c("parcel_type","effect_size"), 
               values_to = "pred_acc", names_pattern = "(.*)_(.*_.*)" ) %>%
  mutate(parcel_type = ifelse(parcel_type == "act", "Activated", "Reverse-Activated"),
         condition = rep("Reading-cog Task", nrow(.))) %>%
  select(-load_insensitive)

rbind(df_vocab, df_pmat, df_reading) %>%
  ggplot(aes(x = effect_size, y = pred_acc, color = parcel_type)) +
  facet_wrap(vars(condition), scales = "free", nrow = 1) + 
  geom_point() + 
  geom_line(aes(group = interaction(condition,parcel_type), color = parcel_type)) + 
  ylim(0, 0.6) + 
  xlab("Parcel Bins based on ES") + 
  ylab("Predictive Accuracy (Measured by r)") + 
  scale_x_discrete(labels=c("load_insensitive" = "Insensitive", 
                            "01_03" = "(0.1,0.3)", "03_05" = "(0.3,0.5)", "05_07" = "(0.5,0.7)", 
                            "07_09" = "(0.7,0.9)", "09_11" = "(0.9,1.1)", "11_13" = "(1.1,1.3)",
                            "13_15" = "(1.3,1.5)"),
                   guide = guide_axis(n.dodge = 2)) + 
  theme_classic() +
  theme(axis.title.x = element_text(size = 10),
        axis.text.x = element_text(size = 6),
        axis.title.y = element_text(size = 10, face = "bold"),
        axis.text.y = element_text(size = 8, face = "bold"), 
        plot.title = element_text(size = 10, hjust = 0.5),
        plot.margin = margin(0,0,0,0,"cm"),
        legend.position = c(0.1, 0.92),
        legend.title = element_blank(),
        strip.text.x = element_text(size = 10, face = 'bold'))  #+ 
  #ggsave("plots/suppmat/schaefer/schaefer_multivariate_facet.svg", width=7, height=2.25)
```

### Use load-effect to guide feature selection
```{r}
rm(list = ls())

plot_feature_selection <- function(df_dir, measure){
  # read in data
  df <- import(here::here(paste0("data/schaefer_permutation/", df_dir)))
  # extract null 
  null <- df %>%
    select(lower, mean, upper, idx)
  # plot
  plot <- 
    df %>%
    ggplot(aes(x = idx, y = observed)) + 
    geom_point(aes(color = parcel_type), size = 0.6) + 
    geom_line(color = "black", size = 0.5) + 
    geom_point(data = null, aes(x = idx, y = mean), alpha = 0.1, color = "gray1", size = 0.6) + 
    geom_line(data = null, aes(x = idx, y = mean), color = "gray1", alpha = 0.1) +
    geom_ribbon(data = null, aes(x = idx, ymin = lower, ymax = upper), fill = "gray1", 
                linetype = 2, alpha = 0.1, inherit.aes = F) + 
    theme_classic() + 
    ylab("Predictive Acc") + 
    xlab("Top n parcels \n (Based on CohenD)") + 
    ggtitle(paste0(measure)) + 
    scale_x_continuous(breaks=seq(0, 60, 10))+ 
    theme(axis.title.x = element_text(size = 10),
          axis.text.x = element_text(size = 8),
          plot.title = element_text(size = 10, hjust = 0.5, face = "bold"),
          axis.text.y = element_text(size = 8), 
          strip.text.x = element_text(size = 10),
          plot.margin = margin(0,0,0,0,"cm"),
          legend.position = "none",
          legend.title = element_blank()) #+
    #ggsave(paste0("plots/suppmat/schaefer/model_", measure, ".svg"), width=3.3, height=1.9)
  
  return(plot)
}

# WM_Task_2bk_Acc
plot_feature_selection("schaefer_feature_selection_permutation_WM_Task_2bk_Acc.csv", "2-back Task")
# PicVocab_AgeAdj
plot_feature_selection("schaefer_feature_selection_permutation_PicVocab_AgeAdj.csv", "Pic-vocab Task")
# PMAT24_A_CR
plot_feature_selection("schaefer_feature_selection_permutation_PMAT24_A_CR.csv", "PMAT Task")
# ReadEng_AgeAdj
plot_feature_selection("schaefer_feature_selection_permutation_ReadEng_AgeAdj.csv", "Reading-cog Task")
# ListSort_AgeAdj
plot_feature_selection("schaefer_feature_selection_permutation_ListSort_AgeAdj.csv", "List-sorting Task")

```

### for plotting purpose 6a
```{r dpi = 300}
rm(list = ls())

# ----------
# Figure 7a
# ----------

# inscanner info 
df_wm <- import(here::here('data/schaefer_permutation/schaefer_feature_selection_permutation_WM_Task_2bk_Acc.csv')) %>%
  mutate(rep("Inscanner(2-back)", nrow(.)))
observe_wm <- df_wm %>%
  select(observed, idx, parcel_type) %>%
  rename("Inscanner(2-back)_predAcc" = observed)
null_wm <- df_wm %>%
    select(lower, mean, upper, idx) %>%
    rename("Inscanner(2-back)_predAcc_lower" = lower, 
           "Inscanner(2-back)_predAcc_mean" = mean,
           "Inscanner(2-back)_predAcc_upper" = upper)

# outscanner info 
df_ls <- import(here::here('data/schaefer_permutation/schaefer_feature_selection_permutation_ListSort_AgeAdj.csv')) %>%
   mutate(rep("Outscanner(list-sorting)", nrow(.)))
observe_ls <- df_ls %>%
  select(observed, idx, parcel_type) %>%
  rename("Outscanner(list-sorting)_predAcc" = observed)
null_ls <- df_ls %>%
    select(lower, mean, upper, idx) %>%
    rename("Outscanner(list-sorting)_predAcc_lower" = lower, 
           "Outscanner(list-sorting)_predAcc_mean" = mean,
           "Outscanner(list-sorting)_predAcc_upper" = upper)

null_cut <- left_join(null_wm, null_ls) %>% 
  pivot_longer(., cols = -idx, names_pattern = "(.*)_predAcc_(.*)", names_to = c("beh_label","value_type"), values_to = "value") %>%
  pivot_wider(., names_from = "value_type", values_from = "value" )

left_join(observe_wm, observe_ls, by = c("idx","parcel_type")) %>% 
  pivot_longer(., cols = c("Inscanner(2-back)_predAcc", "Outscanner(list-sorting)_predAcc"), names_pattern = "(.*)_(.*)", names_to = c("beh_label","value_type"), values_to = "value") %>% 
  ggplot(aes(x = idx, y = value)) + 
  facet_grid(cols = vars(beh_label)) + 
  geom_point(aes(color = parcel_type), size = 0.6) + 
  geom_line(color = "black", size = 0.5) + 
  geom_point(data = null_cut, aes(x = idx, y = mean), alpha = 0.2, color = "grey", size = 0.6) + 
  geom_line(data = null_cut, aes(x = idx, y = mean), color = "grey", size = 0.5) +
  geom_ribbon(data = null_cut, aes(x = idx, ymin = lower, ymax = upper), fill = "grey", 
              linetype = 2, alpha = 0.2, inherit.aes = F) + 
  theme_classic() + 
  ylab("Predictive Acc") + 
  xlab("Top n parcels") + 
  scale_x_continuous(breaks=seq(0, 60, 10))+ 
  theme(axis.title.x = element_text(size = 10),
        axis.text.x = element_text(size = 8),
        axis.title.y = element_text(size = 10),
        axis.text.y = element_text(size = 8), 
        plot.title = element_text(size = 10),
        strip.text.x = element_text(size = 10),
        plot.margin = margin(0,0,0,0,"cm"),
        legend.position = "none",
        legend.title = element_blank())  #+
  #ggsave("plots/fig6_heuristic.svg",  width=3.5, height=1.9)


```
### for supplementary materials plotting:
```{r}
rm(list = ls())

# ----------
# Figure 7a
# ----------

# inscanner info 
df_pmat <- import(here::here('data/schaefer_permutation/schaefer_feature_selection_permutation_PMAT24_A_CR.csv')) %>%
  mutate(rep("PMAT", nrow(.)))
observe_pmat <- df_pmat %>%
  select(observed, idx, parcel_type) %>%
  rename("PMAT_predAcc" = observed)
null_pmat <- df_pmat %>%
    select(lower, mean, upper, idx) %>%
    rename("PMAT_predAcc_lower" = lower, 
           "PMAT_predAcc_mean" = mean,
           "PMAT_predAcc_upper" = upper)

# outscanner info 
df_reading <- import(here::here('data/schaefer_permutation/schaefer_feature_selection_permutation_ReadEng_AgeAdj.csv')) %>%
   mutate(rep("Reading-cog", nrow(.)))
observe_reading <- df_reading %>%
  select(observed, idx, parcel_type) %>%
  rename("Reading-cog_predAcc" = observed)
null_reading <- df_reading %>%
    select(lower, mean, upper, idx) %>%
    rename("Reading-cog_predAcc_lower" = lower, 
           "Reading-cog_predAcc_mean" = mean,
           "Reading-cog_predAcc_upper" = upper)

# outscanner info 
df_vocab <- import(here::here('data/schaefer_permutation/schaefer_feature_selection_permutation_PicVocab_AgeAdj.csv')) %>%
   mutate(rep("Vocab", nrow(.)))
observe_vocab <- df_vocab %>%
  select(observed, idx, parcel_type) %>%
  rename("Vocab_predAcc" = observed)
null_vocab <- df_vocab %>%
    select(lower, mean, upper, idx) %>%
    rename("Vocab_predAcc_lower" = lower, 
           "Vocab_predAcc_mean" = mean,
           "Vocab_predAcc_upper" = upper)

null_cut <- left_join(null_pmat, null_reading) %>% left_join(.,  null_vocab) %>%
  pivot_longer(., cols = -idx, names_pattern = "(.*)_predAcc_(.*)", names_to = c("beh_label","value_type"), values_to = "value") %>%
  pivot_wider(., names_from = "value_type", values_from = "value" )

left_join(observe_pmat, observe_reading,  by = c("idx","parcel_type")) %>% left_join(., observe_vocab, by = c("idx","parcel_type")) %>%
  pivot_longer(., cols = c("PMAT_predAcc", "Reading-cog_predAcc", "Vocab_predAcc"), names_pattern = "(.*)_(.*)", names_to = c("beh_label","value_type"), values_to = "value") %>% 
  ggplot(aes(x = idx, y = value)) + 
  facet_wrap(vars(beh_label), scales = "free", nrow = 1) + 
  geom_point(aes(color = parcel_type), size = 0.6) + 
  geom_line(color = "black", size = 0.5) + 
  geom_point(data = null_cut, aes(x = idx, y = mean), alpha = 0.2, color = "grey", size = 0.6) + 
  geom_line(data = null_cut, aes(x = idx, y = mean), color = "grey", size = 0.5) +
  geom_ribbon(data = null_cut, aes(x = idx, ymin = lower, ymax = upper), fill = "grey", 
              linetype = 2, alpha = 0.2, inherit.aes = F) + 
  theme_classic() + 
  ylab("Predictive Acc") + 
  xlab("Top n parcels") + 
  scale_x_continuous(breaks=seq(0, 60, 10))+ 
  theme(axis.title.x = element_text(size = 10),
        axis.text.x = element_text(size = 8),
        axis.title.y = element_text(size = 10),
        axis.text.y = element_text(size = 8), 
        plot.title = element_text(size = 10),
        strip.text.x = element_text(size = 10),
        plot.margin = margin(0,0,0,0,"cm"),
        legend.position = "none",
        legend.title = element_blank()) #+
  #ggsave("plots/suppmat/schaefer/model_building.svg",  width=7, height=2.25)
```

### for plotting purpose (figure 6b)
```{r}
# ----------
# Figure 7b
# ----------
remove(list = ls())
# pred acc computed with python scripts. See xxxx (script name)
## The predictive accuracy was computed from the python script and copied here for plotting. 
data.frame("measure" = c("Inscanner \n(2-back)","Inscanner \n(2-back)", "Outscanner \n(list-sorting)","Outscanner \n(list-sorting)"), 
           "feature_number" = factor(c("Full", "rename", "Full", "rename")),
           "predictive_accuracy"= c(0.451644173072573, 0.5324083, 0.1776145396326645, 0.2583356)) %>%
  ggplot(data = ., aes(x = measure, y = predictive_accuracy, fill = feature_number)) + 
  #geom_col(width = 0.4, position = "dodge") + 
  geom_bar(stat = "identity", position = position_dodge(), color = 'black') + 
  ylab("Predictive Acc") + 
  xlab("") + 
  theme_minimal() +
  theme(axis.title.x = element_text(size = 10),
        axis.text.x = element_text(size = 8),
        axis.title.y = element_text(size = 10),
        axis.text.y = element_text(size = 8), 
        plot.margin = margin(1,1,0,1,"cm"),
        legend.position = "none",
        legend.title = element_blank()) +
  ylim(0, 0.6) #+
  #ggsave(here::here('plots/model_acc.svg'), width = 2.7, height = 2.5)


```

